{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7901a910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10.428571\n",
       "1         9.500000\n",
       "2        10.769231\n",
       "3         6.800000\n",
       "4         6.800000\n",
       "           ...    \n",
       "10889     8.333333\n",
       "10890    10.666667\n",
       "10891     9.666667\n",
       "10892    10.000000\n",
       "10893     8.500000\n",
       "Length: 10894, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/dnd_chars_all.tsv\", sep=\"\\t\")\n",
    "df['HP'] / df['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "312c8ae9-d8f6-4b2f-b95b-30d255cad242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        10\n",
      "1        10\n",
      "2        21\n",
      "3        16\n",
      "4        16\n",
      "         ..\n",
      "10889    13\n",
      "10890    16\n",
      "10891    19\n",
      "10892    14\n",
      "10893    13\n",
      "Name: AC, Length: 10894, dtype: int64\n",
      "Original Imbalance ratio: 1342.00 (1.0 = perfectly balanced)\n",
      "Pruned Imbalance ratio: 6.58 (1.0 = perfectly balanced)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/dnd_chars_all.tsv\", sep=\"\\t\")\n",
    "df.drop(columns=[\"ip\", \"finger\", \"hash\"], inplace=True)\n",
    "df[\"normalized_race\"] = df[\"processedRace\"].str.strip().str.lower()\n",
    "df[\"normalized_background\"] = df[\"background\"].str.strip().str.lower()\n",
    "print(df['AC'])\n",
    "counts = df['justClass'].value_counts()\n",
    "X = df[['Str', 'Dex', 'Con', 'Int', 'Wis', 'Cha', 'HP', 'AC', 'normalized_race', 'normalized_background', 'processedAlignment', 'level']]\n",
    "y = df['justClass']\n",
    "\n",
    "# Fill-in processedAlignment with Random alignments, maintaining original distribution\n",
    "alignment_dist = X['processedAlignment'].value_counts(normalize=True)\n",
    "na_mask = X['processedAlignment'].isna()\n",
    "X.loc[na_mask, 'processedAlignment'] = np.random.choice(\n",
    "    alignment_dist.index,\n",
    "    size=na_mask.sum(),\n",
    "    p=alignment_dist.values\n",
    ")\n",
    "\n",
    "# Remove classes that don't have enough samples\n",
    "min_samples = 50\n",
    "frequent_classes = counts[counts >= min_samples].index\n",
    "mask = y.isin(frequent_classes)\n",
    "X = X[mask]\n",
    "X['StrCon'] = X['Str'] - X['Con']\n",
    "X['WisInt'] = X['Wis'] - X['Int']\n",
    "X['HPPerLevel'] = X['HP']/X['level']\n",
    "X.drop(['level'], axis=1, inplace=True)\n",
    "y = y[mask]\n",
    "original_counts = df['justClass'].value_counts()\n",
    "max_count = original_counts.max()\n",
    "min_count = original_counts.min()\n",
    "original_imbalance_ratio = max_count / min_count\n",
    "print(f\"Original Imbalance ratio: {original_imbalance_ratio:.2f} (1.0 = perfectly balanced)\")\n",
    "pruned_counts = y.value_counts()\n",
    "max_count = pruned_counts.max()\n",
    "min_count = pruned_counts.min()\n",
    "pruned_imbalance_ratio = max_count / min_count\n",
    "print(f\"Pruned Imbalance ratio: {pruned_imbalance_ratio:.2f} (1.0 = perfectly balanced)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4cc2c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numerical_cols = ['Str', 'Dex', 'Con', 'Int', 'Wis', 'Cha', 'HP', 'AC', 'StrCon', 'WisInt', 'HPPerLevel']\n",
    "categorical_cols = ['normalized_race', 'normalized_background',\n",
    "            'processedAlignment']\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), numerical_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b059369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dummy_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_dummy = cross_val_score(dummy_pipe, X, y, cv=cv, scoring='f1_macro')\n",
    "print(\"5-fold dummy macro-F1:\", cv_dummy.mean())\n",
    "\n",
    "pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", OneVsRestClassifier(LogisticRegression(max_iter=1000)))\n",
    "])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipe, X, y,\n",
    "                         cv=cv,\n",
    "                         scoring=\"f1_macro\")\n",
    "print(\"5-fold macro-F1:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb925f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "number_of_estimators = 100\n",
    "\n",
    "unbalanced_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=number_of_estimators, \n",
    "            random_state=42, \n",
    "        ))\n",
    "])\n",
    "\n",
    "balanced_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=number_of_estimators, \n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        ))\n",
    "])\n",
    "\n",
    "balanced_subsample_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", RandomForestClassifier(\n",
    "            n_estimators=number_of_estimators, \n",
    "            random_state=42,\n",
    "            class_weight='balanced_subsample'\n",
    "        ))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(unbalanced_pipe, X, y,\n",
    "                         cv=cv,\n",
    "                         scoring=\"f1_macro\")\n",
    "predictions = cross_val_predict(unbalanced_pipe, X, y, cv=cv)\n",
    "print(\"Unbalanced f1:\", scores.mean())\n",
    "print(classification_report(y, predictions))\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(balanced_pipe, X, y,\n",
    "                         cv=cv,\n",
    "                         scoring=\"f1_macro\")\n",
    "predictions = cross_val_predict(balanced_pipe, X, y, cv=cv)\n",
    "\n",
    "print(\"Balanced f1:\", scores.mean())\n",
    "print(classification_report(y, predictions))\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(balanced_subsample_pipe, X, y,\n",
    "                         cv=cv,\n",
    "                         scoring=\"f1_macro\")\n",
    "predictions = cross_val_predict(balanced_subsample_pipe, X, y, cv=cv)\n",
    "print(\"Balanced subsample f1:\", scores.mean())\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "scores = cross_val_score(balanced_pipe, X, y, cv=rskf, scoring=\"f1_macro\")\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00140c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "best_pipe = balanced_subsample_pipe\n",
    "best_pipe.fit(X, y)\n",
    "\n",
    "result = permutation_importance(\n",
    "            best_pipe,                  \n",
    "            X, y,\n",
    "            n_repeats=20,\n",
    "            scoring=\"f1_macro\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "         )\n",
    "\n",
    "feature_names = best_pipe.named_steps[\"prep\"].get_feature_names_out()\n",
    "importances   = pd.Series(result.importances_mean, index=X.columns)\n",
    "\n",
    "print(importances)\n",
    "\n",
    "topk = importances.sort_values(ascending=False).head(25)\n",
    "plt.figure(figsize=(8, 10))\n",
    "topk[::-1].plot(kind=\"barh\")\n",
    "plt.xlabel(\"Decrease in macro-F1 when permuted\")\n",
    "plt.title(\"Permutation feature importance (20 repeats)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_pipe.fit(X, y)\n",
    "balanced_pipe.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "ohe = balanced_pipe.named_steps['prep'].named_transformers_['cat']\n",
    "num_features = numerical_cols\n",
    "cat_features = ohe.get_feature_names_out(categorical_cols)\n",
    "all_features = np.concatenate([num_features, cat_features])\n",
    "\n",
    "importances = balanced_pipe.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "feat_importances = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "feat_importances.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccd762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB f1: 0.7500964182527807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Artificer       0.81      0.65      0.72       204\n",
      "   Barbarian       0.83      0.81      0.82       882\n",
      "        Bard       0.66      0.64      0.65       661\n",
      "      Cleric       0.84      0.84      0.84       969\n",
      "       Druid       0.76      0.78      0.77       706\n",
      "     Fighter       0.72      0.73      0.73      1342\n",
      "        Monk       0.75      0.74      0.74       692\n",
      "     Paladin       0.83      0.80      0.81       838\n",
      "      Ranger       0.67      0.65      0.66       709\n",
      "       Rogue       0.72      0.79      0.76      1187\n",
      "    Sorcerer       0.78      0.73      0.75       617\n",
      "     Warlock       0.64      0.64      0.64       623\n",
      "      Wizard       0.85      0.87      0.86       719\n",
      "\n",
      "    accuracy                           0.76     10149\n",
      "   macro avg       0.76      0.74      0.75     10149\n",
      "weighted avg       0.76      0.76      0.76     10149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "xgb_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))\n",
    "])\n",
    "\n",
    "X_t = preprocess.fit_transform(X)\n",
    "y_t = label_encoder.fit_transform(y)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(xgb_pipe, X, y_t,\n",
    "                         cv=cv,\n",
    "                         scoring=\"f1_macro\")\n",
    "predictions = cross_val_predict(xgb_pipe, X, y_t, cv=cv)\n",
    "print(\"XGB f1:\", scores.mean())\n",
    "print(classification_report(y, label_encoder.inverse_transform(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d77e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro Score: 0.7823845165291362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Artificer       0.93      0.68      0.79        57\n",
      "   Barbarian       0.87      0.85      0.86       204\n",
      "        Bard       0.68      0.64      0.66       168\n",
      "      Cleric       0.86      0.86      0.86       236\n",
      "       Druid       0.80      0.82      0.81       167\n",
      "     Fighter       0.75      0.76      0.75       353\n",
      "        Monk       0.80      0.76      0.78       184\n",
      "     Paladin       0.82      0.80      0.81       221\n",
      "      Ranger       0.70      0.66      0.68       168\n",
      "       Rogue       0.76      0.84      0.80       313\n",
      "    Sorcerer       0.83      0.83      0.83       145\n",
      "     Warlock       0.61      0.65      0.63       139\n",
      "      Wizard       0.92      0.90      0.91       183\n",
      "\n",
      "    accuracy                           0.79      2538\n",
      "   macro avg       0.79      0.77      0.78      2538\n",
      "weighted avg       0.79      0.79      0.79      2538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "        (\"prep\",  preprocess),\n",
    "        (\"model\", xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42))\n",
    "])\n",
    "\n",
    "y_t = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_t, random_state=42)\n",
    "\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_pipe.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"F1 Macro Score:\", f1)\n",
    "\n",
    "print(classification_report(label_encoder.inverse_transform(y_test), label_encoder.inverse_transform(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b04e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a8bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
